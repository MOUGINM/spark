{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa3d373-0952-4dbd-82be-5f26d76d334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier, NaiveBayes\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4022e9f2-b4b1-42c8-b3f9-0868023a2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser la session Spark\n",
    "spark = SparkSession.builder.appName(\"MushroomClassification\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65166d9-7e08-43ea-867a-41641d6facd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles dans le DataFrame :\n",
      "['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "data = spark.read.csv(\"mushrooms.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Nettoyer les noms des colonnes pour enlever les espaces\n",
    "data = data.toDF(*[col.strip() for col in data.columns])\n",
    "\n",
    "# Vérifier les colonnes\n",
    "print(\"Colonnes disponibles dans le DataFrame :\")\n",
    "print(data.columns)\n",
    "\n",
    "# Vérification si la colonne \"class\" est présente\n",
    "if 'class' not in data.columns:\n",
    "    raise ValueError(\"La colonne 'class' est manquante dans le DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f48e59e-352b-407c-a1a4-a5364ec00a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-traitement\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(data) \n",
    "            for column in data.columns if column != 'class']\n",
    "assembler = VectorAssembler(inputCols=[column+\"_index\" for column in data.columns if column != 'class'], \n",
    "                            outputCol=\"features\")\n",
    "label_indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\").fit(data)\n",
    "\n",
    "# Pipeline de transformation\n",
    "pipeline = Pipeline(stages=indexers + [assembler, label_indexer])\n",
    "data_transformed = pipeline.fit(data).transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b04e28f-42bb-4834-919c-31c017a05b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "train_data, test_data = data_transformed.randomSplit([0.8, 0.2], seed=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddaff1fb-8383-4d08-abfb-88391dd8ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser une liste pour stocker les résultats\n",
    "results = {}\n",
    "\n",
    "# Modèles à tester\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Gradient-Boosted Trees\": GBTClassifier(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Naive Bayes\": NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ed08fa-bfbe-404a-9767-add89bf700dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser un dictionnaire pour stocker les métriques\n",
    "metrics_results = {}\n",
    "\n",
    "# Évaluer chaque modèle\n",
    "for model_name, model in models.items():\n",
    "    # Entraîner le modèle\n",
    "    model_trained = model.fit(train_data)\n",
    "    \n",
    "    # Faire des prédictions\n",
    "    predictions = model_trained.transform(test_data)\n",
    "\n",
    "    # Évaluer avec ROC\n",
    "    binary_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "    roc_auc = binary_evaluator.evaluate(predictions)\n",
    "\n",
    "    # Évaluer avec précision, rappel et F1-score\n",
    "    multi_evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "    multi_evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    multi_evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    \n",
    "    precision = multi_evaluator_precision.evaluate(predictions)\n",
    "    recall = multi_evaluator_recall.evaluate(predictions)\n",
    "    f1_score = multi_evaluator_f1.evaluate(predictions)\n",
    "\n",
    "    # Stocker les résultats dans le dictionnaire\n",
    "    metrics_results[model_name] = {\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd4a722-a000-4faf-bae8-98da67059fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef6176b6-4fb6-406a-a749-02f6db652a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         ROC AUC  Precision    Recall  F1 Score\n",
      "Logistic Regression     0.986211   0.986276  0.986250  0.986249\n",
      "Random Forest           0.999369   0.999376  0.999375  0.999375\n",
      "Gradient-Boosted Trees  0.999369   0.999376  0.999375  0.999375\n",
      "Decision Tree           0.994318   0.994437  0.994375  0.994375\n",
      "Naive Bayes             0.925980   0.927391  0.926250  0.926180\n"
     ]
    }
   ],
   "source": [
    "# Afficher les résultats\n",
    "# for model_name, metrics in metrics_results.items():\n",
    "#     print(f\"{model_name} Metrics:\")\n",
    "#     print(f\"  ROC AUC: {metrics['ROC AUC']:.4f}\")\n",
    "#     print(f\"  Precision: {metrics['Precision']:.4f}\")\n",
    "#     print(f\"  Recall: {metrics['Recall']:.4f}\")\n",
    "#     print(f\"  F1 Score: {metrics['F1 Score']:.4f}\")\n",
    "import pandas as pd\n",
    "\n",
    "# Créer un DataFrame à partir des résultats des métriques\n",
    "metrics_df = pd.DataFrame(metrics_results).T  # Transpose pour avoir les modèles en lignes\n",
    "\n",
    "# Afficher le tableau des métriques\n",
    "print(metrics_df)\n",
    "# Arrêter la session Spark\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b19a79c8-2417-4ada-bd19-aa4635afa60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         ROC AUC  Precision    Recall  F1 Score\n",
      "Random Forest           0.999369   0.999376  0.999375  0.999375\n",
      "Gradient-Boosted Trees  0.999369   0.999376  0.999375  0.999375\n",
      "Decision Tree           0.994318   0.994437  0.994375  0.994375\n",
      "Logistic Regression     0.986211   0.986276  0.986250  0.986249\n",
      "Naive Bayes             0.925980   0.927391  0.926250  0.926180\n",
      "Mean                    0.981049   0.981371  0.981125  0.981111\n"
     ]
    }
   ],
   "source": [
    "# Calculer la moyenne des métriques pour chaque colonne\n",
    "mean_metrics = metrics_df.mean()\n",
    "\n",
    "# Ajouter la ligne de moyenne au DataFrame\n",
    "sorted_metrics_df.loc['Mean'] = mean_metrics\n",
    "\n",
    "# Afficher le tableau avec la ligne de moyenne\n",
    "print(sorted_metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e30e0f-1eba-4e29-9a9a-cf10881d73fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
